{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b918608",
   "metadata": {},
   "source": [
    "### Import external modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56ffdffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.vec_env import VecMonitor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d0a2c9",
   "metadata": {},
   "source": [
    "### Add mbt-gym to path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "387934ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cb89dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mbt_gym.agents.BaselineAgents import CarteaJaimungalMmAgent\n",
    "from mbt_gym.gym.helpers.generate_trajectory import generate_trajectory\n",
    "from mbt_gym.gym.StableBaselinesTradingEnvironment import StableBaselinesTradingEnvironment\n",
    "from mbt_gym.gym.TradingEnvironment import TradingEnvironment\n",
    "from mbt_gym.gym.wrappers import *\n",
    "from mbt_gym.rewards.RewardFunctions import CjCriterion, CjMmCriterion\n",
    "from mbt_gym.stochastic_processes.midprice_models import *\n",
    "from mbt_gym.stochastic_processes.fill_probability_models import *\n",
    "from mbt_gym.stochastic_processes.arrival_models import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535d65b0",
   "metadata": {},
   "source": [
    "### Add parameters for limit order market making environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41296b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "terminal_time = 1.0\n",
    "arrival_rate = 10.0\n",
    "n_steps = int(10 * terminal_time * arrival_rate)\n",
    "phi = 0.5\n",
    "alpha = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "707d4586",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cj_env_Poisson(num_trajectories:int = 1):    \n",
    "    fill_exponent = 1\n",
    "    sigma = 0.1\n",
    "    initial_inventory = (-4,5)\n",
    "    initial_price = 100\n",
    "    step_size = terminal_time/n_steps\n",
    "    timestamps = np.linspace(0, terminal_time, n_steps + 1)\n",
    "    env_params = dict(terminal_time=terminal_time, \n",
    "                      n_steps=n_steps,\n",
    "                      initial_inventory = initial_inventory,\n",
    "                      midprice_model = BrownianMotionMidpriceModel(volatility=sigma, \n",
    "                                                                   terminal_time=terminal_time, \n",
    "                                                                   step_size=step_size, \n",
    "                                                                   initial_price=initial_price, \n",
    "                                                                   num_trajectories=num_trajectories),\n",
    "                      arrival_model = PoissonArrivalModel(intensity=np.array([100.0, 100.0]), \n",
    "                                                          step_size=step_size),\n",
    "                      fill_probability_model = ExponentialFillFunction(fill_exponent=fill_exponent, \n",
    "                                                                       step_size=step_size, \n",
    "                                                                       num_trajectories=num_trajectories),\n",
    "                      reward_function = CjMmCriterion(phi, alpha),\n",
    "                      max_inventory=n_steps,\n",
    "                      num_trajectories=num_trajectories)\n",
    "    return TradingEnvironment(**env_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0aa98a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cj_env(num_trajectories:int = 1):    \n",
    "    fill_exponent = 1\n",
    "    sigma = 0.1\n",
    "    initial_inventory = (-4,5)\n",
    "    initial_price = 100\n",
    "    step_size = terminal_time/n_steps\n",
    "    timestamps = np.linspace(0, terminal_time, n_steps + 1)\n",
    "    env_params = dict(terminal_time=terminal_time, \n",
    "                      n_steps=n_steps,\n",
    "                      initial_inventory = initial_inventory,\n",
    "                      midprice_model = BrownianMotionMidpriceModel(volatility=sigma, \n",
    "                                                                   terminal_time=terminal_time, \n",
    "                                                                   step_size=step_size, \n",
    "                                                                   initial_price=initial_price, \n",
    "                                                                   num_trajectories=num_trajectories),\n",
    "                      arrival_model = HawkesArrivalModel(num_trajectories=num_trajectories, step_size=step_size),\n",
    "                      fill_probability_model = ExponentialFillFunction(fill_exponent=fill_exponent, \n",
    "                                                                       step_size=step_size, \n",
    "                                                                       num_trajectories=num_trajectories),\n",
    "                      reward_function = CjMmCriterion(phi, alpha),\n",
    "                      max_inventory=n_steps,\n",
    "                      num_trajectories=num_trajectories)\n",
    "    return TradingEnvironment(**env_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d29022e",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "num_trajectories = 10000\n",
    "env = ReduceStateSizeWrapper(get_cj_env(num_trajectories), [1,2,4,5])\n",
    "sb_env = StableBaselinesTradingEnvironment(trading_env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e40a80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_exponent = 1\n",
    "sigma = 0.1\n",
    "initial_inventory = (-4,5)\n",
    "initial_price = 100\n",
    "step_size = terminal_time/n_steps\n",
    "timestamps = np.linspace(0, terminal_time, n_steps + 1)\n",
    "env_params = dict(terminal_time=terminal_time, \n",
    "                    n_steps=n_steps,\n",
    "                    initial_inventory = initial_inventory,\n",
    "                    midprice_model = BrownianMotionMidpriceModel(volatility=sigma, \n",
    "                                                               terminal_time=terminal_time, \n",
    "                                                               step_size=step_size, \n",
    "                                                               initial_price=initial_price, \n",
    "                                                               num_trajectories=num_trajectories),\n",
    "                    arrival_model = HawkesArrivalModel(num_trajectories=num_trajectories),\n",
    "                    fill_probability_model = ExponentialFillFunction(fill_exponent=fill_exponent, \n",
    "                                                                   step_size=step_size, \n",
    "                                                                   num_trajectories=num_trajectories),\n",
    "                    reward_function = CjMmCriterion(phi, alpha),\n",
    "                    max_inventory=n_steps,\n",
    "                    num_trajectories=num_trajectories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "426116c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = TradingEnvironment(**env_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d657c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cj_agent = CarteaJaimungalMmAgent(env=get_cj_env_Poisson(), max_inventory = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f837dc9",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "# Monitor sb_env\n",
    "sb_env = VecMonitor(sb_env)\n",
    "# Add directory for tensorboard logging \n",
    "tensorboard_logdir = \"./tensorboard/PPO-learning-Hawkes/\"\n",
    "best_model_path = \"./SB_models/PPO-best-Hawkes\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3106df91",
   "metadata": {},
   "source": [
    "### Define PPO policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5d0e1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.9/site-packages/stable_baselines3/common/policies.py:458: UserWarning: As shared layers in the mlp_extractor are deprecated and will be removed in SB3 v1.8.0, you should now pass directly a dictionary and not a list (net_arch=dict(pi=..., vf=...) instead of net_arch=[dict(pi=..., vf=...)])\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "policy_kwargs = dict(net_arch=[dict(pi=[64, 64], vf=[128, 128])])\n",
    "PPO_params = {\"policy\":'MlpPolicy', \"env\": sb_env, \"verbose\":1, \n",
    "              \"policy_kwargs\":policy_kwargs, \n",
    "              \"tensorboard_log\":tensorboard_logdir,\n",
    "              \"batch_size\": int(n_steps * num_trajectories / 20), \n",
    "              \"n_steps\": int(n_steps)} #256 before (batch size)\n",
    "callback_params = dict(eval_env=sb_env, n_eval_episodes = 2048, \n",
    "                       eval_freq = 200,#200 before  (n_eval_episodes)\n",
    "                       best_model_save_path = best_model_path, \n",
    "                       deterministic=True)\n",
    "\n",
    "callback = EvalCallback(**callback_params)\n",
    "model = PPO(**PPO_params, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01707612",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.learn(total_timesteps = 1_000_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d74b6cd",
   "metadata": {},
   "source": [
    "## Comparing the learnt policy to the optimal policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc4d5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mbt_gym.agents.SbAgent import SbAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80b78c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = SbAgent(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcb28e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "inventories = np.arange(-3,4,1)\n",
    "bid_actions = {}\n",
    "ask_actions = {}\n",
    "intensities=[5,10,20]\n",
    "for intensity in intensities:\n",
    "    bid_actions[intensity] = []\n",
    "    ask_actions[intensity] = []\n",
    "    for inventory in inventories:\n",
    "        bid_action, ask_action = np.reshape(model.predict([inventory,0.5, intensity, intensity], deterministic=True)[0], 2)    \n",
    "        bid_actions[intensity].append(bid_action)\n",
    "        ask_actions[intensity].append(ask_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb6bb5cc",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "BrownianMotionMidpriceModel.step_size = 0.001,  but env.step_size = 0.01",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cj_agent \u001b[38;5;241m=\u001b[39m CarteaJaimungalMmAgent(env\u001b[38;5;241m=\u001b[39m\u001b[43mget_cj_env_Poisson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, max_inventory \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m)\n",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36mget_cj_env_Poisson\u001b[0;34m(num_trajectories)\u001b[0m\n\u001b[1;32m      7\u001b[0m timestamps \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0\u001b[39m, terminal_time, n_steps \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      8\u001b[0m env_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(terminal_time\u001b[38;5;241m=\u001b[39mterminal_time, \n\u001b[1;32m      9\u001b[0m                   n_steps\u001b[38;5;241m=\u001b[39mn_steps,\n\u001b[1;32m     10\u001b[0m                   initial_inventory \u001b[38;5;241m=\u001b[39m initial_inventory,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m                   max_inventory\u001b[38;5;241m=\u001b[39mn_steps,\n\u001b[1;32m     22\u001b[0m                   num_trajectories\u001b[38;5;241m=\u001b[39mnum_trajectories)\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mTradingEnvironment\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43menv_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/mbt_gym/notebooks/../mbt_gym/gym/TradingEnvironment.py:77\u001b[0m, in \u001b[0;36mTradingEnvironment.__init__\u001b[0;34m(self, terminal_time, n_steps, reward_function, midprice_model, arrival_model, fill_probability_model, price_impact_model, action_type, initial_cash, initial_inventory, max_inventory, max_cash, max_stock_price, max_depth, max_speed, half_spread, random_start, info_calculator, seed, num_trajectories)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitial_inventory \u001b[38;5;241m=\u001b[39m initial_inventory\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_inventory \u001b[38;5;241m=\u001b[39m max_inventory\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrng \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mdefault_rng(seed)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m seed:\n",
      "File \u001b[0;32m~/Documents/GitHub/mbt_gym/notebooks/../mbt_gym/gym/TradingEnvironment.py:367\u001b[0m, in \u001b[0;36mTradingEnvironment._check_params\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_type \u001b[38;5;129;01min\u001b[39;00m ACTION_TYPES\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m process \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstochastic_processes\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[0;32m--> 367\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39misclose(process\u001b[38;5;241m.\u001b[39mstep_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_size, atol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m, rtol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m), (\n\u001b[1;32m    368\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmidprice_model)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.step_size = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprocess\u001b[38;5;241m.\u001b[39mstep_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    369\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but env.step_size = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    370\u001b[0m     )\n\u001b[1;32m    371\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m process\u001b[38;5;241m.\u001b[39mnum_trajectories \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_trajectories, (\n\u001b[1;32m    372\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe stochastic processes given to an instance of TradingEnvironment must match the number of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    373\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrajectories specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    374\u001b[0m     )\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreward_function, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstep_size\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[0;31mAssertionError\u001b[0m: BrownianMotionMidpriceModel.step_size = 0.001,  but env.step_size = 0.01"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a344c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Cartea Jaimungal action\n",
    "cj_bid_actions = []\n",
    "cj_ask_actions = []\n",
    "for inventory in inventories:\n",
    "    bid_action, ask_action = cj_agent.get_action(np.array([[0,inventory,0.5]])).reshape(-1)\n",
    "    cj_bid_actions.append(bid_action)\n",
    "    cj_ask_actions.append(ask_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40e9388",
   "metadata": {},
   "outputs": [],
   "source": [
    "bid_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615c8e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"k\", \"r\", \"b\"]\n",
    "\n",
    "for i, intensity in enumerate(intensities):\n",
    "    plt.plot(inventories, bid_actions[intensity], label = f\"bid - lambda = {intensity}\", color = colors[i])\n",
    "    plt.plot(inventories, ask_actions[intensity], label = f\"ask - lambda = {intensity}\", color = colors[i], linestyle = \"--\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57074bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps = np.arange(0,1 + 0.01, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27489a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bid_actions = {}\n",
    "ask_actions = {}\n",
    "for inventory in inventories:\n",
    "    bid_actions[inventory] = []\n",
    "    ask_actions[inventory] = []\n",
    "    for timestamp in timestamps:\n",
    "        bid_action, ask_action = agent.get_action(np.array([inventory, timestamp]))\n",
    "        bid_actions[inventory].append(bid_action)\n",
    "        ask_actions[inventory].append(ask_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dcb1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for inventory in inventories:\n",
    "    plt.plot(timestamps, bid_actions[inventory], label=f\"bid: q = {inventory}\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59213c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "for inventory in inventories:\n",
    "    plt.plot(timestamps, ask_actions[inventory], label=f\"ask: q = {inventory}\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a188943d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"trained_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5b31b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = PPO.load(\"trained_model.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ef2d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703b2796",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
