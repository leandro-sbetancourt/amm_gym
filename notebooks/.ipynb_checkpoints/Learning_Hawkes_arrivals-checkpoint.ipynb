{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b918608",
   "metadata": {},
   "source": [
    "### Import external modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56ffdffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.vec_env import VecMonitor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d0a2c9",
   "metadata": {},
   "source": [
    "### Add mbt-gym to path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "387934ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cb89dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mbt_gym.agents.BaselineAgents import CarteaJaimungalMmAgent\n",
    "from mbt_gym.gym.helpers.generate_trajectory import generate_trajectory\n",
    "from mbt_gym.gym.StableBaselinesTradingEnvironment import StableBaselinesTradingEnvironment\n",
    "from mbt_gym.gym.TradingEnvironment import TradingEnvironment\n",
    "from mbt_gym.gym.wrappers import *\n",
    "from mbt_gym.rewards.RewardFunctions import CjCriterion, CjMmCriterion\n",
    "from mbt_gym.stochastic_processes.midprice_models import *\n",
    "from mbt_gym.stochastic_processes.fill_probability_models import *\n",
    "from mbt_gym.stochastic_processes.arrival_models import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535d65b0",
   "metadata": {},
   "source": [
    "### Add parameters for limit order market making environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41296b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "terminal_time = 1.0\n",
    "arrival_rate = 10.0\n",
    "n_steps = int(10 * terminal_time * arrival_rate)\n",
    "phi = 0.5\n",
    "alpha = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "314922ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cj_env_poisson(num_trajectories:int = 1):    \n",
    "    fill_exponent = 1\n",
    "    sigma = 0.1\n",
    "    initial_inventory = (-4,5)\n",
    "    initial_price = 100\n",
    "    step_size = 1/n_steps\n",
    "    print(step_size)\n",
    "    timestamps = np.linspace(0, terminal_time, n_steps + 1)\n",
    "    env_params = dict(terminal_time=terminal_time, \n",
    "                      n_steps=n_steps,\n",
    "                      initial_inventory = initial_inventory,\n",
    "                      midprice_model = BrownianMotionMidpriceModel(volatility=sigma, \n",
    "                                                                   terminal_time=terminal_time, \n",
    "                                                                   step_size=step_size, \n",
    "                                                                   initial_price=initial_price, \n",
    "                                                                   num_trajectories=num_trajectories),\n",
    "                      arrival_model = PoissonArrivalModel(intensity=np.array([100,100]), step_size=step_size),\n",
    "                      fill_probability_model = ExponentialFillFunction(fill_exponent=fill_exponent, \n",
    "                                                                       step_size=step_size, \n",
    "                                                                       num_trajectories=num_trajectories),\n",
    "                      reward_function = CjMmCriterion(phi, alpha),\n",
    "                      max_inventory=n_steps,\n",
    "                      num_trajectories=num_trajectories)\n",
    "    return TradingEnvironment(**env_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0aa98a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cj_env(num_trajectories:int = 1):    \n",
    "    fill_exponent = 1\n",
    "    sigma = 0.1\n",
    "    initial_inventory = (-4,5)\n",
    "    initial_price = 100\n",
    "    step_size = 1/n_steps\n",
    "    timestamps = np.linspace(0, terminal_time, n_steps + 1)\n",
    "    env_params = dict(terminal_time=terminal_time, \n",
    "                      n_steps=n_steps,\n",
    "                      initial_inventory = initial_inventory,\n",
    "                      midprice_model = BrownianMotionMidpriceModel(volatility=sigma, \n",
    "                                                                   terminal_time=terminal_time, \n",
    "                                                                   step_size=step_size, \n",
    "                                                                   initial_price=initial_price, \n",
    "                                                                   num_trajectories=num_trajectories),\n",
    "                      arrival_model = HawkesArrivalModel(num_trajectories=num_trajectories),\n",
    "                      fill_probability_model = ExponentialFillFunction(fill_exponent=fill_exponent, \n",
    "                                                                       step_size=step_size, \n",
    "                                                                       num_trajectories=num_trajectories),\n",
    "                      reward_function = CjCriterion(phi, alpha),\n",
    "                      max_inventory=n_steps,\n",
    "                      num_trajectories=num_trajectories)\n",
    "    return TradingEnvironment(**env_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d29022e",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "num_trajectories = 10000\n",
    "env = ReduceStateSizeWrapper(get_cj_env(num_trajectories), [1,2,4,5])\n",
    "sb_env = StableBaselinesTradingEnvironment(trading_env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f837dc9",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "# Monitor sb_env\n",
    "sb_env = VecMonitor(sb_env)\n",
    "# Add directory for tensorboard logging \n",
    "tensorboard_logdir = \"./tensorboard/PPO-learning-Hawkes/\"\n",
    "best_model_path = \"./SB_models/PPO-best-Hawkes\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3106df91",
   "metadata": {},
   "source": [
    "### Define PPO policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5d0e1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.9/site-packages/stable_baselines3/common/policies.py:458: UserWarning: As shared layers in the mlp_extractor are deprecated and will be removed in SB3 v1.8.0, you should now pass directly a dictionary and not a list (net_arch=dict(pi=..., vf=...) instead of net_arch=[dict(pi=..., vf=...)])\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "policy_kwargs = dict(net_arch=[dict(pi=[64, 64], vf=[128, 128])])\n",
    "PPO_params = {\"policy\":'MlpPolicy', \"env\": sb_env, \"verbose\":1, \n",
    "              \"policy_kwargs\":policy_kwargs, \n",
    "              \"tensorboard_log\":tensorboard_logdir,\n",
    "              \"batch_size\": int(n_steps * num_trajectories / 20), \n",
    "              \"n_steps\": int(n_steps)} #256 before (batch size)\n",
    "callback_params = dict(eval_env=sb_env, n_eval_episodes = 2048, \n",
    "                       eval_freq = 1000000*5,#200 before  (n_eval_episodes)\n",
    "                       best_model_save_path = best_model_path, \n",
    "                       deterministic=True)\n",
    "\n",
    "callback = EvalCallback(**callback_params)\n",
    "model = PPO(**PPO_params, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01707612",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.learn(total_timesteps = 100_000) #100_000_000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d74b6cd",
   "metadata": {},
   "source": [
    "## Comparing the learnt policy to the optimal policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc4d5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mbt_gym.agents.SbAgent import SbAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80b78c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = SbAgent(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcb28e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "inventories = np.arange(-3,4,1)\n",
    "bid_actions = {}\n",
    "ask_actions = {}\n",
    "intensities=[5,10,20]\n",
    "for intensity in intensities:\n",
    "    bid_actions[intensity] = []\n",
    "    ask_actions[intensity] = []\n",
    "    for inventory in inventories:\n",
    "        bid_action, ask_action = np.reshape(model.predict([inventory,0.5, intensity, intensity], deterministic=True)[0], 2)    \n",
    "        bid_actions[intensity].append(bid_action)\n",
    "        ask_actions[intensity].append(ask_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf669d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "env=get_cj_env_poisson()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6bb5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cj_agent = CarteaJaimungalMmAgent(env=get_cj_env_poisson(), max_inventory=10)\n",
    "\n",
    "#cj_agent = CarteaJaimungalAgent(phi = phi, alpha= alpha, env=get_cj_env())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a344c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Cartea Jaimungal action\n",
    "cj_bid_actions = []\n",
    "cj_ask_actions = []\n",
    "for inventory in inventories:\n",
    "    bid_action, ask_action = cj_agent.get_action(np.array([[0,inventory,0.5]])).reshape(-1)\n",
    "    cj_bid_actions.append(bid_action)\n",
    "    cj_ask_actions.append(ask_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40e9388",
   "metadata": {},
   "outputs": [],
   "source": [
    "bid_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615c8e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"k\", \"r\", \"b\"]\n",
    "\n",
    "for i, intensity in enumerate(intensities):\n",
    "    plt.plot(inventories, bid_actions[intensity], label = f\"bid - lambda = {intensity}\", color = colors[i])\n",
    "    plt.plot(inventories, ask_actions[intensity], label = f\"ask - lambda = {intensity}\", color = colors[i], linestyle = \"--\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57074bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps = np.arange(0,1 + 0.01, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27489a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bid_actions = {}\n",
    "ask_actions = {}\n",
    "for inventory in inventories:\n",
    "    bid_actions[inventory] = []\n",
    "    ask_actions[inventory] = []\n",
    "    for timestamp in timestamps:\n",
    "        bid_action, ask_action = agent.get_action(np.array([inventory, timestamp]))\n",
    "        bid_actions[inventory].append(bid_action)\n",
    "        ask_actions[inventory].append(ask_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dcb1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for inventory in inventories:\n",
    "    plt.plot(timestamps, bid_actions[inventory], label=f\"bid: q = {inventory}\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59213c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "for inventory in inventories:\n",
    "    plt.plot(timestamps, ask_actions[inventory], label=f\"ask: q = {inventory}\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a188943d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"trained_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5b31b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = PPO.load(\"trained_model.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ef2d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
