{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08005fcb",
   "metadata": {},
   "source": [
    "# Avellaneda-Stoikov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96ce4fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\") # This version of the notebook is in the subfolder \"notebooks\" of the repo\n",
    "\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "from mbt_gym.gym.TradingEnvironment import TradingEnvironment\n",
    "from mbt_gym.gym.Traders import AmmTrader\n",
    "\n",
    "from mbt_gym.agents.BaselineAgents import *\n",
    "from mbt_gym.gym.helpers.generate_trajectory import generate_trajectory\n",
    "from mbt_gym.gym.helpers.plotting import *\n",
    "from mbt_gym.agents.BaselineAgents import CarteaJaimungalMmAgent\n",
    "from mbt_gym.gym.helpers.generate_trajectory import generate_trajectory\n",
    "from mbt_gym.gym.StableBaselinesTradingEnvironment import StableBaselinesTradingEnvironment\n",
    "from mbt_gym.gym.wrappers import *\n",
    "from mbt_gym.rewards.RewardFunctions import CjCriterion, CjMmCriterion\n",
    "from mbt_gym.stochastic_processes.midprice_models import *\n",
    "from mbt_gym.stochastic_processes.fill_probability_models import *\n",
    "from mbt_gym.stochastic_processes.arrival_models import *\n",
    "import torch\n",
    "#print(torch.cuda.is_available())\n",
    "#print(torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287e3f0d",
   "metadata": {},
   "source": [
    "## Avellaneda-Stoikov Optimal Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24d68e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "terminal_time = 1.0\n",
    "arrival_rate = 10.0\n",
    "n_steps = int(10 * terminal_time * arrival_rate)\n",
    "phi = 0.5\n",
    "alpha = 0.001\n",
    "\n",
    "num_trajectories = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd56c4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_amm_env_Poisson(num_trajectories:int = 1):    \n",
    "    fill_exponent = 1\n",
    "    sigma = 0.001\n",
    "    initial_inventory = 1_000\n",
    "    initial_price = 100\n",
    "    unit_size = 1.0\n",
    "    max_depth = 5*1/fill_exponent\n",
    "    step_size = terminal_time/n_steps\n",
    "    midprice_model = AmmSelfContainedMidpriceModel(jump_size_L=1.0, \n",
    "                                                   unit_size = unit_size,\n",
    "                                                   terminal_time=terminal_time, \n",
    "                                                       step_size=step_size, \n",
    "                                                       initial_price=initial_price, \n",
    "                                                       num_trajectories=num_trajectories)\n",
    "    arrival_model = PoissonArrivalModel(intensity=np.array([arrival_rate, arrival_rate]), step_size=step_size)\n",
    "    fill_probability_model = ExponentialFillFunction(fill_exponent=fill_exponent, \n",
    "                                                                       step_size=step_size, \n",
    "                                                                       num_trajectories=num_trajectories)\n",
    "    AMMtrader = AmmTrader(midprice_model = midprice_model, arrival_model = arrival_model, \n",
    "                                fill_probability_model = fill_probability_model,\n",
    "                                num_trajectories = num_trajectories, max_depth = max_depth, unit_size = unit_size)\n",
    "    \n",
    "    env_params = dict(terminal_time=terminal_time, \n",
    "                      n_steps=n_steps,\n",
    "                      initial_inventory = initial_inventory,\n",
    "                      midprice_model = midprice_model,\n",
    "                      arrival_model = arrival_model,\n",
    "                      fill_probability_model = fill_probability_model,\n",
    "                      trader = AMMtrader,\n",
    "                      reward_function = CjMmCriterion(phi, alpha),\n",
    "                      normalise_action_space = False,\n",
    "                      normalise_observation_space = False,\n",
    "                      num_trajectories=num_trajectories)\n",
    "    return TradingEnvironment(**env_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0c171a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "amm_env = get_amm_env_Poisson()\n",
    "as_agent = FayLeoMmAgent(env=amm_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7dd86124",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leandro/Documents/GitHub/amm_gym/notebooks/../mbt_gym/agents/BaselineAgents.py:259: RuntimeWarning: divide by zero encountered in log\n",
      "  return 1 / self.kappa * np.log(omega_function)\n",
      "/Users/leandro/Documents/GitHub/amm_gym/notebooks/../mbt_gym/agents/BaselineAgents.py:253: RuntimeWarning: invalid value encountered in add\n",
      "  deltas[:, BID_INDEX] = (1 / self.kappa - h_plus_one + h_0 + self.large_depth * max_inventory_bid - 1/self.env.midprice_model.jump_size_L).reshape(-1)\n",
      "/Users/leandro/Documents/GitHub/amm_gym/notebooks/../mbt_gym/agents/BaselineAgents.py:254: RuntimeWarning: invalid value encountered in add\n",
      "  deltas[:, ASK_INDEX] = (1 / self.kappa - h_minus_one + h_0 + self.large_depth * max_inventory_ask + 1/self.env.midprice_model.jump_size_L).reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clipping agent's cash from [nan] to [nan].\n",
      "Clipping agent's cash from [nan] to [nan].\n",
      "Clipping agent's cash from [nan] to [nan].\n",
      "Clipping agent's cash from [nan] to [nan].\n",
      "Clipping agent's cash from [nan] to [nan].\n",
      "Clipping agent's cash from [nan] to [nan].\n",
      "Clipping agent's cash from [nan] to [nan].\n",
      "Clipping agent's cash from [nan] to [nan].\n",
      "Clipping agent's cash from [nan] to [nan].\n",
      "Clipping agent's cash from [nan] to [nan].\n",
      "Clipping agent's cash from [nan] to [nan].\n",
      "Clipping agent's cash from [nan] to [nan].\n",
      "Clipping agent's cash from [nan] to [nan].\n",
      "Clipping agent's cash from [nan] to [nan].\n",
      "Clipping agent's cash from [nan] to [nan].\n",
      "Clipping agent's cash from [nan] to [nan].\n",
      "Clipping agent's cash from [nan] to [nan].\n",
      "Clipping agent's cash from [nan] to [nan].\n",
      "Clipping agent's cash from [nan] to [nan].\n",
      "Clipping agent's cash from [nan] to [nan].\n",
      "Clipping agent's cash from [nan] to [nan].\n",
      "Clipping agent's cash from [nan] to [nan].\n",
      "Clipping agent's cash from [nan] to [nan].\n",
      "Clipping agent's cash from [nan] to [nan].\n",
      "Clipping agent's cash from [nan] to [nan].\n",
      "Clipping agent's cash from [nan] to [nan].\n",
      "Clipping agent's cash from [nan] to [nan].\n",
      "Clipping agent's cash from [nan] to [nan].\n",
      "Clipping agent's cash from [nan] to [nan].\n",
      "Clipping agent's cash from [nan] to [nan].\n",
      "Clipping agent's cash from [nan] to [nan].\n",
      "Clipping agent's cash from [nan] to [nan].\n",
      "Clipping agent's cash from [nan] to [nan].\n",
      "Clipping agent's cash from [nan] to [nan].\n",
      "Clipping agent's cash from [nan] to [nan].\n",
      "Clipping agent's cash from [nan] to [nan].\n",
      "Clipping agent's cash from [nan] to [nan].\n",
      "Clipping agent's cash from [nan] to [nan].\n",
      "Clipping agent's cash from [nan] to [nan].\n",
      "Clipping agent's cash from [nan] to [nan].\n",
      "Clipping agent's cash from [nan] to [nan].\n",
      "Clipping agent's cash from [nan] to [nan].\n",
      "Clipping agent's cash from [nan] to [nan].\n",
      "Clipping agent's cash from [nan] to [nan].\n",
      "Clipping agent's cash from [nan] to [nan].\n",
      "Clipping agent's cash from [nan] to [nan].\n",
      "Clipping agent's cash from [nan] to [nan].\n",
      "Clipping agent's cash from [nan] to [nan].\n",
      "Clipping agent's cash from [nan] to [nan].\n",
      "Clipping agent's cash from [nan] to [nan].\n",
      "Clipping agent's cash from [nan] to [nan].\n",
      "Clipping agent's cash from [nan] to [nan].\n",
      "Clipping agent's cash from [nan] to [nan].\n",
      "Clipping agent's cash from [nan] to [nan].\n",
      "Clipping agent's cash from [nan] to [nan].\n",
      "Clipping agent's cash from [nan] to [nan].\n",
      "Clipping agent's cash from [nan] to [nan].\n",
      "Clipping agent's cash from [nan] to [nan].\n",
      "Clipping agent's cash from [nan] to [nan].\n",
      "Clipping agent's cash from [nan] to [nan].\n",
      "Clipping agent's cash from [nan] to [nan].\n",
      "Clipping agent's cash from [nan] to [nan].\n",
      "Clipping agent's cash from [nan] to [nan].\n",
      "Clipping agent's cash from [nan] to [nan].\n",
      "Clipping agent's cash from [nan] to [nan].\n",
      "Clipping agent's cash from [nan] to [nan].\n",
      "Clipping agent's cash from [nan] to [nan].\n",
      "Clipping agent's cash from [nan] to [nan].\n",
      "Clipping agent's cash from [nan] to [nan].\n",
      "Clipping agent's cash from [nan] to [nan].\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m seed \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mplot_trajectory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamm_env\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_agent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/amm_gym/notebooks/../mbt_gym/gym/helpers/plotting.py:22\u001b[0m, in \u001b[0;36mplot_trajectory\u001b[0;34m(env, agent, seed)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_trajectory\u001b[39m(env: gym\u001b[38;5;241m.\u001b[39mEnv, agent: Agent, seed: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m# assert env.num_trajectories == 1, \"Plotting a trajectory can only be done when env.num_trajectories == 1.\"\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     timestamps \u001b[38;5;241m=\u001b[39m get_timestamps(env)\n\u001b[0;32m---> 22\u001b[0m     observations, actions, rewards \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_trajectory\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     action_dim \u001b[38;5;241m=\u001b[39m actions\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     24\u001b[0m     colors \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mg\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/GitHub/amm_gym/notebooks/../mbt_gym/gym/helpers/generate_trajectory.py:25\u001b[0m, in \u001b[0;36mgenerate_trajectory\u001b[0;34m(env, agent, seed, include_log_probs)\u001b[0m\n\u001b[1;32m     23\u001b[0m     action, log_prob \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mget_action(obs, include_log_probs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m     action \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m obs, reward, done, _ \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[1;32m     27\u001b[0m actions[:, :, count] \u001b[38;5;241m=\u001b[39m action\n",
      "File \u001b[0;32m~/Documents/GitHub/amm_gym/notebooks/../mbt_gym/agents/BaselineAgents.py:237\u001b[0m, in \u001b[0;36mFayLeoMmAgent.get_action\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    235\u001b[0m current_time \u001b[38;5;241m=\u001b[39m state[\u001b[38;5;241m0\u001b[39m, TIME_INDEX]\n\u001b[1;32m    236\u001b[0m inventories \u001b[38;5;241m=\u001b[39m state[:, INVENTORY_INDEX]\n\u001b[0;32m--> 237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_calculate_deltas\u001b[49m\u001b[43m(\u001b[49m\u001b[43minventories\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minventories\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurrent_time\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/amm_gym/notebooks/../mbt_gym/agents/BaselineAgents.py:241\u001b[0m, in \u001b[0;36mFayLeoMmAgent._calculate_deltas\u001b[0;34m(self, current_time, inventories)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_calculate_deltas\u001b[39m(\u001b[38;5;28mself\u001b[39m, current_time: \u001b[38;5;28mfloat\u001b[39m, inventories: np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m    240\u001b[0m     deltas \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_trajectories, \u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m--> 241\u001b[0m     h_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_calculate_ht\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_time\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;66;03m# If the inventory goes above the max level, we quote a large depth to bring it back and quote on the opposite\u001b[39;00m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;66;03m# side as if we had an inventory equal to sign(inventory) * self.max_inventory.\u001b[39;00m\n\u001b[1;32m    244\u001b[0m     indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_inventory \u001b[38;5;241m+\u001b[39m inventories, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_inventory)\n",
      "File \u001b[0;32m~/Documents/GitHub/amm_gym/notebooks/../mbt_gym/agents/BaselineAgents.py:258\u001b[0m, in \u001b[0;36mFayLeoMmAgent._calculate_ht\u001b[0;34m(self, current_time)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_calculate_ht\u001b[39m(\u001b[38;5;28mself\u001b[39m, current_time: \u001b[38;5;28mfloat\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[0;32m--> 258\u001b[0m     omega_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_calculate_omega\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_time\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkappa \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(omega_function)\n",
      "File \u001b[0;32m~/Documents/GitHub/amm_gym/notebooks/../mbt_gym/agents/BaselineAgents.py:263\u001b[0m, in \u001b[0;36mFayLeoMmAgent._calculate_omega\u001b[0;34m(self, current_time)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_calculate_omega\u001b[39m(\u001b[38;5;28mself\u001b[39m, current_time: \u001b[38;5;28mfloat\u001b[39m):\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;124;03m\"\"\"This is Equation (10.11) from [CJP15].\"\"\"\u001b[39;00m\n\u001b[0;32m--> 263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmatmul(\u001b[43mexpm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ma_matrix\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mterminal_time\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcurrent_time\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mz_vector)\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.9/site-packages/scipy/linalg/_matfuncs.py:378\u001b[0m, in \u001b[0;36mexpm\u001b[0;34m(A)\u001b[0m\n\u001b[1;32m    376\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# generic\u001b[39;00m\n\u001b[1;32m    377\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(s):\n\u001b[0;32m--> 378\u001b[0m             eAw \u001b[38;5;241m=\u001b[39m \u001b[43meAw\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43meAw\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;66;03m# Zero out the entries from np.empty in case of triangular input\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (lu[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (lu[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "seed = 1\n",
    "plot_trajectory(amm_env, as_agent, seed = seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed76675c",
   "metadata": {},
   "source": [
    "### Comparing the results to the Avellaneda Stoikov paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b4a440",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trajectories = 100000\n",
    "vec_env = get_as_env(num_trajectories)\n",
    "vec_as = AvellanedaStoikovAgent(risk_aversion=0.1, env=vec_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea588e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "observations, actions, rewards = generate_trajectory(vec_env, vec_as)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b71326",
   "metadata": {},
   "outputs": [],
   "source": [
    "results, fig, total_rewards = generate_results_table_and_hist(vec_env=vec_env,agent=vec_as)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb4ef4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bd8801",
   "metadata": {},
   "source": [
    "These results look similar to Table 2 of Avellaneda and Stoikov. It is interesting that the agent **does** quote a negative spread sometimes, which _could_ be interpreted as taking liquidity but then the model should possibly be changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26723547",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5b4c4b",
   "metadata": {},
   "source": [
    "### The effect of increasing risk aversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e273095",
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_aversions = [0.01,0.1,0.5,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2ef0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rewards_dict = dict()\n",
    "for risk_aversion in risk_aversions:\n",
    "    vec_as = AvellanedaStoikovAgent(risk_aversion=risk_aversion, env=vec_env)\n",
    "    _,_,total_rewards_dict[risk_aversion] = generate_results_table_and_hist(vec_env=vec_env,agent=vec_as);   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f20eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"r\", \"g\", \"b\", \"c\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f793a053",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(20,10))\n",
    "for risk_aversion, color in zip(risk_aversions,colors):\n",
    "    sns.histplot(total_rewards_dict[risk_aversion], label=f\"risk-aversion {risk_aversion}\", stat = \"density\", bins = 50, ax=ax, color=color)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1eacfa0",
   "metadata": {},
   "source": [
    "**Note, it is hard to argue that the risk-averse agent is outperforming the non risk-averse agent in these cases...**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe476dd",
   "metadata": {},
   "source": [
    "## The Cartea-Jaimungal agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7db5fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cj_agent = CarteaJaimungalAgent(phi=0.1, alpha=0.001,env=as_env, max_inventory=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f66749",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_trajectory(as_env, cj_agent, seed = seed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "7fdb8041655b3dc02b7fba31b82b0328083461cc824a5f662da36f4ff301447b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
